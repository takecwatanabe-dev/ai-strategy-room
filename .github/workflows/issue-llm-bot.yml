# Issue LLM Bot
# Version: v1.0.0
# Build: 2025-12-14 00:04 JST
# Changes:
# - YAML崩れを避けるため Issue情報はGITHUB_EVENT_PATHから読む
# - [TASK] タイトルのみ反応
# - opened / reopened どちらでも起動

name: Issue LLM Bot

on:
  issues:
    types: [opened, reopened]

permissions:
  contents: read
  issues: write

concurrency:
  group: issue-llm-bot-${{ github.event.issue.number }}
  cancel-in-progress: true

jobs:
  reply:
    if: startsWith(github.event.issue.title, '[TASK]')
    runs-on: ubuntu-latest

    steps:
      - name: Generate reply (OpenAI -> fallback Gemini) and comment
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, json, urllib.request, urllib.error

          def http_json(url, method="GET", headers=None, data=None, timeout=30):
              headers = headers or {}
              if data is not None:
                  if isinstance(data, (dict, list)):
                      data = json.dumps(data).encode("utf-8")
                      headers.setdefault("Content-Type", "application/json")
                  elif isinstance(data, str):
                      data = data.encode("utf-8")
              req = urllib.request.Request(url, method=method, headers=headers, data=data)
              try:
                  with urllib.request.urlopen(req, timeout=timeout) as r:
                      return r.status, r.read().decode("utf-8", errors="replace")
              except urllib.error.HTTPError as e:
                  body = e.read().decode("utf-8", errors="replace") if e.fp else ""
                  return e.code, body
              except Exception as e:
                  return 0, str(e)

          # Read event payload safely (avoids YAML multiline issues)
          event_path = os.getenv("GITHUB_EVENT_PATH", "")
          if not event_path:
              raise RuntimeError("GITHUB_EVENT_PATH is missing")
          with open(event_path, "r", encoding="utf-8") as f:
              event = json.load(f)

          issue = event.get("issue", {}) or {}
          title = (issue.get("title") or "").strip()
          body = (issue.get("body") or "").strip()
          number = issue.get("number")
          repo = os.getenv("GITHUB_REPOSITORY", "").strip()

          if not repo or not number:
              raise RuntimeError("Missing repo or issue number")

          prompt = f"""あなたはプロジェクト補助AIです。
          ユーザーは「コピペ量を減らしたい」ので、回答は短く・実行しやすく。

          以下のIssue内容から、次を日本語Markdownで返してください:
          1) 要旨（1〜2行）
          2) 次の1アクション（クリック/入力まで具体）
          3) うまくいかない時の分岐（A/Bで2つまで）
          4) 注意点（秘密情報は貼らない等、1〜2行）

          --- Issue Title ---
          {title}

          --- Issue Body ---
          {body}
          """

          def generate_openai(text):
              api_key = (os.getenv("OPENAI_API_KEY") or "").strip()
              if not api_key:
                  raise RuntimeError("OPENAI_API_KEY missing")
              url = "https://api.openai.com/v1/chat/completions"
              payload = {
                  "model": "gpt-4o-mini",
                  "messages": [
                      {"role": "system", "content": "You are a helpful assistant."},
                      {"role": "user", "content": text}
                  ],
                  "temperature": 0.2
              }
              st, resp = http_json(url, method="POST", headers={
                  "Authorization": f"Bearer {api_key}",
                  "Content-Type": "application/json",
              }, data=payload)
              if st != 200:
                  raise RuntimeError(f"OpenAI error {st}: {resp[:300]}")
              obj = json.loads(resp)
              return obj["choices"][0]["message"]["content"].strip()

          def generate_gemini(text):
              api_key = (os.getenv("GEMINI_API_KEY") or "").strip()
              if not api_key:
                  raise RuntimeError("GEMINI_API_KEY missing")
              url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
              payload = {
                  "contents": [{"role": "user", "parts": [{"text": text}]}],
                  "generationConfig": {"temperature": 0.2}
              }
              st, resp = http_json(url, method="POST", headers={"Content-Type": "application/json"}, data=payload)
              if st != 200:
                  raise RuntimeError(f"Gemini error {st}: {resp[:300]}")
              obj = json.loads(resp)
              cand = (obj.get("candidates") or [])
              if not cand:
                  raise RuntimeError("Gemini no candidates")
              parts = (cand[0].get("content", {}) or {}).get("parts", []) or []
              out = "".join(p.get("text", "") for p in parts).strip()
              if not out:
                  raise RuntimeError("Gemini empty output")
              return out

          try:
              reply = generate_openai(prompt)
              used = "OpenAI"
          except Exception as e1:
              try:
                  reply = generate_gemini(prompt)
                  used = "Gemini"
              except Exception as e2:
                  reply = f"自動返信に失敗しました。\n\n- OpenAI: {e1}\n- Gemini: {e2}"
                  used = "ERROR"

          comment_body = (reply.strip() + f"\n\n---\n_bot: {used}_").strip()

          gh_token = (os.getenv("GITHUB_TOKEN") or "").strip()
          if not gh_token:
              raise RuntimeError("GITHUB_TOKEN missing")

          gh_url = f"https://api.github.com/repos/{repo}/issues/{number}/comments"
          st, resp = http_json(gh_url, method="POST", headers={
              "Authorization": f"Bearer {gh_token}",
              "Accept": "application/vnd.github+json",
              "X-GitHub-Api-Version": "2022-11-28",
              "User-Agent": "issue-llm-bot"
          }, data={"body": comment_body})

          if st not in (200, 201):
              raise RuntimeError(f"GitHub comment failed {st}: {resp[:500]}")
          print("OK")
          PY
